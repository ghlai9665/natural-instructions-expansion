{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wiki_auto (/Users/garylai/.cache/huggingface/datasets/wiki_auto/auto_acl/1.0.0/5ffdd9fc62422d29bd02675fb9606f77c1251ee17169ac10b143ce07ef2f4db8)\n",
      "100%|██████████| 1/1 [00:00<00:00, 176.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# get instances\n",
    "dataset = load_dataset(\n",
    "    'wiki_auto', 'auto_acl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "model = CrossEncoder('cross-encoder/stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_score(normal_sentence, simple_sentence):\n",
    "#     return model.predict([normal_sentence, sample['simple_sentence'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:19,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for sample in tqdm(zip(dataset['full'][:50]['normal_sentence'], dataset['full'][:50]['simple_sentence'])):\n",
    "    normal_sentence, simple_sentence = sample\n",
    "    score = model.predict([normal_sentence, simple_sentence])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7096, 0.8300, 0.6466, 0.9433, 0.7912, 0.7776, 0.8060, 0.9277, 0.9156,\n",
       "        0.6349, 0.8082, 0.6108, 0.7853, 0.7917, 0.8554, 0.7975, 0.9674, 0.7456,\n",
       "        0.8347, 0.5539, 0.6691, 0.7091, 0.8786, 0.8974, 0.5886, 0.5590, 0.8940,\n",
       "        0.6805, 0.8174, 0.7294, 0.8589, 0.9721, 0.8991, 0.7420, 0.8947, 0.9384,\n",
       "        0.8461, 0.6881, 0.8158, 0.7774, 0.7708, 0.9630, 0.6442, 0.7259, 0.4262,\n",
       "        0.7064, 0.8131, 0.6779, 0.6815, 0.8355])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_tensor = torch.tensor(scores); score_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_scores, topk_indices = torch.topk(score_tensor, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{31: 0.9721257090568542,\n",
       " 16: 0.9674012660980225,\n",
       " 41: 0.9630268216133118,\n",
       " 3: 0.9432664513587952,\n",
       " 35: 0.9384129047393799,\n",
       " 7: 0.9276638031005859,\n",
       " 8: 0.9155656099319458,\n",
       " 32: 0.8990707397460938,\n",
       " 23: 0.8974476456642151,\n",
       " 34: 0.8946980834007263,\n",
       " 26: 0.893998920917511,\n",
       " 22: 0.8785606026649475,\n",
       " 30: 0.8589243292808533,\n",
       " 14: 0.8553726673126221,\n",
       " 36: 0.8461111187934875,\n",
       " 49: 0.8355098962783813,\n",
       " 18: 0.8347379565238953,\n",
       " 1: 0.8300175666809082,\n",
       " 28: 0.817444384098053,\n",
       " 38: 0.8157970905303955,\n",
       " 46: 0.8130649924278259,\n",
       " 10: 0.8082419037818909,\n",
       " 6: 0.8059822916984558,\n",
       " 15: 0.7974823713302612,\n",
       " 13: 0.7916831374168396,\n",
       " 4: 0.791235089302063,\n",
       " 12: 0.7853291630744934,\n",
       " 5: 0.7775927782058716,\n",
       " 39: 0.7774439454078674,\n",
       " 40: 0.770824134349823,\n",
       " 17: 0.7455523610115051,\n",
       " 33: 0.7420403957366943,\n",
       " 29: 0.7293545603752136,\n",
       " 43: 0.7259481549263,\n",
       " 0: 0.7095543146133423,\n",
       " 21: 0.7090914845466614,\n",
       " 45: 0.7063785791397095,\n",
       " 37: 0.6881066560745239,\n",
       " 48: 0.6814740896224976,\n",
       " 27: 0.6804964542388916,\n",
       " 47: 0.6778984665870667,\n",
       " 20: 0.6690515875816345,\n",
       " 2: 0.6465914249420166,\n",
       " 42: 0.6441697478294373,\n",
       " 9: 0.6349310874938965,\n",
       " 11: 0.6107897162437439,\n",
       " 24: 0.588610827922821,\n",
       " 25: 0.5590397715568542,\n",
       " 19: 0.5539358854293823,\n",
       " 44: 0.42619410157203674}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_score = {}\n",
    "for sample in zip(topk_indices, topk_scores):\n",
    "    index, score = sample\n",
    "    index_to_score[int(index)] = float(score)\n",
    "\n",
    "index_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_longer_normal(difference=100):\n",
    "    # to be selected, normal sentence must be at least 10 characters longer\n",
    "    longer_normal = []\n",
    "    for i in topk_indices:\n",
    "        index = int(i)\n",
    "        if (len(dataset['full'][index]['normal_sentence']) - len(dataset['full'][index]['simple_sentence'])) > difference:\n",
    "            longer_normal.append(index)\n",
    "    return longer_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 13, 43, 0, 20, 25]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "longer_normal = select_longer_normal()\n",
    "print(longer_normal)\n",
    "print(len(longer_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds = dataset['full'].select(longer_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7259481549263\n"
     ]
    }
   ],
   "source": [
    "i = 43\n",
    "normal_sentence, simple_sentence = dataset['full'][i]['normal_sentence'], dataset['full'][i]['simple_sentence']\n",
    "score = model.predict([normal_sentence, simple_sentence]); print(f\"score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "normal_sentence: A tank car -LRB- International Union of Railways -LRB- UIC -RRB- : tank wagon -RRB- is a type of railroad car -LRB- UIC : railway car -RRB- or rolling stock designed to transport liquid and gaseous commodities .\n",
      " \n",
      "simple_sentence: A tank car or tank wagon is a type of railroad car designed to transport liquids or gases .\n",
      " \n",
      "original_index: 35 \n",
      "\n",
      "score:  0.9384129047393799\n",
      "--------------------------------------------------------------------------------\n",
      "normal_sentence: The Society for Worldwide Interbank Financial Telecommunication -LRB- SWIFT -RRB- , legally S.W.I.F.T. SCRL , provides a network that enables financial institutions worldwide to send and receive information about financial transactions in a secure , standardized and reliable environment .\n",
      " \n",
      "simple_sentence: The Society for Worldwide Interbank Financial Telecommunication -LRB- SWIFT -RRB- is an international communication network used by the banking and financial industries .\n",
      " \n",
      "original_index: 13 \n",
      "\n",
      "score:  0.7916831374168396\n",
      "--------------------------------------------------------------------------------\n",
      "normal_sentence: The Straits of Florida , Florida Straits , or Florida Strait is a strait located south-southeast of the North American mainland , generally accepted to be between the Gulf of Mexico and the Atlantic Ocean , and between the Florida Keys -LRB- U.S. -RRB- and Cuba .\n",
      " \n",
      "simple_sentence: The Straits of Florida -LRB- or Florida Straits -RRB- is a strait between the Florida Keys and Cuba .\n",
      " \n",
      "original_index: 43 \n",
      "\n",
      "score:  0.7259481549263\n",
      "--------------------------------------------------------------------------------\n",
      "normal_sentence: Pterocarpus indicus -LRB- commonly known as Amboyna wood , Malay padauk , Papua New Guinea rosewood , Philippine mahogany , Andaman redwood , Burmese rosewood , narra , angsana , or Pashu padauk -RRB- is a species of \" Pterocarpus \" native to southeastern Asia , northern Australasia , and the western Pacific Ocean islands , in Cambodia , southernmost China , East Timor , Indonesia , Malaysia , Papua New Guinea , the Philippines , the Ryukyu Islands , the Solomon Islands , Thailand , and Vietnam .\n",
      " \n",
      "simple_sentence: Pterocarpus indicus -LRB- commonly known as Amboyna wood , Malay padauk , Papua New Guinea rosewood , Philippine mahogany , Andaman redwood , Burmese rosewood , narra or Pashu padauk -RRB- is a species of \" Pterocarpus \" native to southeastern Asia .\n",
      " \n",
      "original_index: 0 \n",
      "\n",
      "score:  0.7095543146133423\n",
      "--------------------------------------------------------------------------------\n",
      "normal_sentence: The Mercedes-Benz Axor was a truck manufactured by Mercedes-Benz designed to fill the gap between the premium Actros tractors and the mostly rigid Atego trucks and was targeted at fleet customers .\n",
      " \n",
      "simple_sentence: The Mercedes-Benz Axor was a truck built by Mercedes-Benz from roughly 2001 to 2008 .\n",
      " \n",
      "original_index: 20 \n",
      "\n",
      "score:  0.6690515875816345\n",
      "--------------------------------------------------------------------------------\n",
      "normal_sentence: Streets of Rage -LRB- ヘ ゙ アナックル 怒りの鉄拳 , Bea Nakkuru : Ikari no Tekken , \" Bare Knuckle : Furious Iron Fist \" -RRB- is a side-scrolling beat ' em up video game developed and published by Sega for the Mega Drive / Genesis in 1991 .\n",
      " \n",
      "simple_sentence: Streets of Rage is a beat ' em up game released on the Sega Mega Drive .\n",
      " \n",
      "original_index: 25 \n",
      "\n",
      "score:  0.5590397715568542\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(zip(filtered_ds['normal_sentence'], filtered_ds['simple_sentence'])):\n",
    "    normal_sentence, simple_sentence = sample\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"normal_sentence: {normal_sentence} \\nsimple_sentence: {simple_sentence} \\noriginal_index: {longer_normal[i]} \\n\" )\n",
    "    print(\"score: \", index_to_score[longer_normal[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}