{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset e2e_nlg (/Users/garylai/.cache/huggingface/datasets/e2e_nlg/default/0.0.0/bfeceb720929c2705bd227d1cfe5eaaab102a0bdac10dad618dac1e00c737430)\n",
      "100%|██████████| 3/3 [00:00<00:00, 163.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# get instances\n",
    "dataset = load_dataset('e2e_nlg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42061"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset['train']; len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        key, value = s[:start-1],s[start:end]\n",
    "        return key, value\n",
    "    except ValueError:\n",
    "        return \"nan\", \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_representation(sample):\n",
    "    # parse data\n",
    "    pairs = sample['meaning_representation'].split(\", \")\n",
    "    data = {}\n",
    "    for pair in pairs: \n",
    "        key, value = parse(pair, \"[\", \"]\")\n",
    "        data[key] = value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_subject(sample):\n",
    "    data = parse_representation(sample)\n",
    "    return data['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance(sample):\n",
    "    return {\n",
    "        \"input\": sample['human_reference'],\n",
    "        \"output\": get_sentence_subject(sample)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meaning_representation': 'name[The Vaults], eatType[pub], priceRange[more than £30], customer rating[5 out of 5], near[Café Adriatic]',\n",
       " 'human_reference': 'The Vaults pub near Café Adriatic has a 5 star rating.  Prices start at £30.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_sentence_entity(data, sentence):\n",
    "    near, name = data[\"near\"], data[\"name\"]\n",
    "    sentence = sentence.replace(near, \"xxx\")\n",
    "    sentence = sentence.replace(name, \"yyy\")\n",
    "    sentence = sentence.replace(\"xxx\", name)\n",
    "    sentence = sentence.replace(\"yyy\", near)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  The Vaults pub near Café Adriatic has a 5 star rating.  Prices start at £30.\n",
      "swap_sentence_entity:  Café Adriatic pub near The Vaults has a 5 star rating.  Prices start at £30.\n"
     ]
    }
   ],
   "source": [
    "# sample = dataset[0]\n",
    "# sentence = sample['human_reference']\n",
    "# data = parse_representation(sample)\n",
    "# print(\"sentence: \", sentence)\n",
    "# print(\"swap_sentence_entity: \", swap_sentence_entity(data, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42061/42061 [00:01<00:00, 21327.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Instances = []\n",
    "unique_sentences = set()\n",
    "unique_names = set()\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    sample = dataset[i]\n",
    "    sentence = sample['human_reference']\n",
    "    # prevent duplicates\n",
    "    if sentence in unique_sentences:\n",
    "        continue\n",
    "    else: \n",
    "        unique_sentences.add(sentence)\n",
    "\n",
    "    # only get sentences with multiple named entities\n",
    "    data = parse_representation(sample)\n",
    "    # get sentences sufficiently long / complex \n",
    "    if len(sentence) > 0:\n",
    "        if \"name\" not in data or \"near\" not in data:\n",
    "            continue\n",
    "        # if there's a duplicate, check if swapping \"name\" and \"near\" resolves it\n",
    "        if data[\"name\"] in unique_names and i % 1000 != 0:\n",
    "            if data[\"near\"] in unique_names: continue\n",
    "            else:\n",
    "                unique_names.add(data[\"near\"])\n",
    "                Instances.append(\n",
    "                    {\n",
    "                        \"input\": swap_sentence_entity(data, sentence), \n",
    "                        \"output\": data[\"near\"]\n",
    "                    }\n",
    "                )\n",
    "        else: \n",
    "            unique_names.add(data[\"name\"])\n",
    "            Instances.append(\n",
    "                {\n",
    "                    \"input\": sentence, \n",
    "                    \"output\": data[\"name\"]\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "# print(Instances)\n",
    "print(len(Instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'All Bar One',\n",
       " 'Burger King',\n",
       " 'Café Adriatic',\n",
       " 'Café Brazil',\n",
       " 'Café Rouge',\n",
       " 'Clare Hall',\n",
       " 'Raja Indian Cuisine',\n",
       " 'Ranch',\n",
       " 'The Rice Boat',\n",
       " 'The Six Bells',\n",
       " 'The Sorrento',\n",
       " 'Yippee Noodle Bar'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_nears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alimentum',\n",
       " 'Aromi',\n",
       " 'Bibimbap House',\n",
       " 'Blue Spice',\n",
       " 'Browns Cambridge',\n",
       " 'Clowns',\n",
       " 'Cocum',\n",
       " 'Cotto',\n",
       " 'Fitzbillies',\n",
       " 'Giraffe',\n",
       " 'Green Man',\n",
       " 'Loch Fyne',\n",
       " 'Midsummer House',\n",
       " 'Strada',\n",
       " 'Taste of Cambridge',\n",
       " 'The Cambridge Blue',\n",
       " 'The Cricketers',\n",
       " 'The Dumpling Tree',\n",
       " 'The Eagle',\n",
       " 'The Golden Curry',\n",
       " 'The Golden Palace',\n",
       " 'The Mill',\n",
       " 'The Olive Grove',\n",
       " 'The Phoenix',\n",
       " 'The Plough',\n",
       " 'The Punter',\n",
       " 'The Rice Boat',\n",
       " 'The Twenty Two',\n",
       " 'The Vaults',\n",
       " 'The Waterman',\n",
       " 'The Wrestlers',\n",
       " 'Travellers Rest Beefeater',\n",
       " 'Wildwood',\n",
       " 'Zizzi'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import deque\n",
    "# def process_sentence(sample):\n",
    "#     sentence = sample['human_reference']\n",
    "#     # parse data\n",
    "#     pairs = sample['meaning_representation'].split(\", \")\n",
    "#     data = {}\n",
    "#     for pair in pairs: \n",
    "#         key, value = parse(pair, \"[\", \"]\")\n",
    "#         data[key] = value\n",
    "\n",
    "#     # check entities\n",
    "#     entities = [\"name\", \"near\", \"area\"]\n",
    "#     found_entities = []\n",
    "\n",
    "#     # get input sentence (add <> around entities)\n",
    "#     processed_sentence = sentence\n",
    "#     for entity in entities: \n",
    "#         if entity in data and data[entity] in processed_sentence:\n",
    "#             processed_sentence = processed_sentence.replace(data[entity], \"<\" + data[entity] + \">\")\n",
    "#             found_entities.append(entity)\n",
    "\n",
    "#     # sort entities by position\n",
    "#     sorted_entities = deque()\n",
    "#     earlest_position = float('inf')\n",
    "#     for entity in found_entities:\n",
    "#         position = processed_sentence.find(data[entity])\n",
    "#         if position < earlest_position:\n",
    "#             earlest_position = position\n",
    "#             sorted_entities.appendleft(entity)\n",
    "#         else:\n",
    "#             sorted_entities.append(entity)\n",
    "    \n",
    "#     # map entity to labels (output)\n",
    "#     entity_to_label = {\n",
    "#         \"name\": \"venue\",\n",
    "#         \"near\": \"venue\",\n",
    "#         \"area\": \"area\"\n",
    "#     }\n",
    "#     output = [entity_to_label[entity] for entity in sorted_entities]\n",
    "\n",
    "#     return {\n",
    "#         \"input\": processed_sentence,\n",
    "#         \"output\": output\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_sentences = []\n",
    "# for i in tqdm(range(3000)):\n",
    "#     processed_sentences.append(process_sentence(dataset[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_json = {\n",
    "    \"Contributors\": [\n",
    "        \"Gary Haizhi Lai\"\n",
    "    ],\n",
    "    \"Source\": [\n",
    "        \"e2e\"\n",
    "    ],\n",
    "    \"Categories\": [\n",
    "        \"Text Generation\"\n",
    "    ],\n",
    "    \"Definition\": \"In this task, we ask you to identify the named entity that is the subject of the sentence. Note that there could be multiple named entities in the sentence - you must correctly pick the one that is the sentence's subject.\",\n",
    "    \"Positive Examples\": [\n",
    "        {\n",
    "            \"input\": \"The Eagle is an inexpensive coffee shop near Burger King and the river. It is family-friendly and serves pasta.\",\n",
    "            \"output\": \"The Eagle\",\n",
    "            \"explanation\": \"The correct named entity is identified as the subject of the sentence.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"There is a pub called Strada which serves Italian food right across the street from Yippee Noodle Bar and has a 5 out of 5 customer rating.\",\n",
    "            \"output\": \"Strada\",\n",
    "            \"explanation\": \"The correct named entity is identified as the subject of the sentence. Yippee Noodle Bar is also a named entity but it's not the subject.\"\n",
    "        },\n",
    "    ],\n",
    "    \"Negative Examples\": [\n",
    "        {\n",
    "            \"input\": \"Dig Inn, located near Panda Express, is a highly rated restaurant among students from Columbia University.\",\n",
    "            \"output\": \"Panda Express\",\n",
    "            \"explanation\": \"While Panda Express is a named entity, it is not the subject of the sentence.\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Korea BBQ 669 is an expensive, family-friendly Korean restaurant located near the Bistro Cafe\",\n",
    "            \"output\": \"Bistro Cafe\",\n",
    "            \"explanation\": \"Bistro Cafe is not the subject of the sentence\", \n",
    "        },\n",
    "    ],\n",
    "    \"Instances\": Instances\n",
    "}\n",
    "\n",
    "# export\n",
    "with open('task951_e2e_text_generation.json', 'w') as fp:\n",
    "    final_json = json.dumps(task_json, indent=4, ensure_ascii=False)\n",
    "    print(final_json, file=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81668ee86a9ded77c95d3063bdc2e99dfb7753f240420397bfcb90599fd7ffdc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('commonlit': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}